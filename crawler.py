import time
import os
import pandas as pd
import subprocess 
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.keys import Keys
from datetime import datetime

# ======================================================
# [ì„¤ì •]
# ======================================================
FILE_NAME = "electlink_voc.csv"
SEARCH_KEYWORDS = ["ì¼ë ‰ë§í¬", "ì›Œí„°", "ì±„ë¹„", "ì´ë¸Œì´ì‹œìŠ¤"] 

# [í•µì‹¬] ê²€ìƒ‰ ê²°ê³¼ê°€ ë§ì•„ ë” ê¹Šê²Œ(2~3í˜ì´ì§€ ë¶„ëŸ‰) ì°¾ì•„ë³¼ í‚¤ì›Œë“œ ì§€ì •
DEEP_SEARCH_KEYWORDS = ["ì›Œí„°", "ì±„ë¹„"]

EXCLUDE_WORDS = ["íŒë‹ˆë‹¤", "ì‚½ë‹ˆë‹¤", "ë§¤ì…", "í¬ë ˆë”§", "ì–‘ë„", "ì¿ í°", "íŒë§¤", "êµ¬ë§¤"]
TARGET_CAFE_KEYWORDS = ["í…ŒìŠ¬ë¼", "ì „ê¸°ì°¨", "EV", "ì•„ì´ì˜¤ë‹‰"] 
# ======================================================

data_list = []

print(f"ğŸš€ ê³ ì„±ëŠ¥ í¬ë¡¤ëŸ¬ ì‹œì‘ (ì¼ë°˜/ì‹¬ì¸µ ê²€ìƒ‰ ìë™ ì „í™˜)")
print(f"âš ï¸  ì£¼ì˜: ë°˜ë“œì‹œ ê¸°ì¡´ '{FILE_NAME}' íŒŒì¼ì„ ì‚­ì œí•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”!")

options = webdriver.ChromeOptions()
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
options.add_argument("--headless")  # [ì¤‘ìš”] í™”ë©´ ì—†ì´ ì‹¤í–‰
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-gpu")

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
time.sleep(2)

try:
    for keyword in SEARCH_KEYWORDS:
        print(f"\nğŸ” '{keyword}' ê²€ìƒ‰ ì¤‘...")
        base_url = "https://search.naver.com/search.naver?ssc=tab.cafe.all&st=date&nso=so%3Add%2Cp%3Aall&query="
        driver.get(base_url + keyword)
        time.sleep(3) 

        # -----------------------------------------------------------
        # [ìˆ˜ì •] ìŠ¤í¬ë¡¤ ë¡œì§ ê³ ë„í™” (ì¼ë°˜ vs ì‹¬ì¸µ)
        # -----------------------------------------------------------
        if keyword in DEEP_SEARCH_KEYWORDS:
            print(f"   ğŸ‘‰ '{keyword}'ëŠ” ë°ì´í„°ê°€ ë§ì•„ 3í˜ì´ì§€ ë¶„ëŸ‰ê¹Œì§€ ê¹Šê²Œ íŒë‹ˆë‹¤... (ì•½ 20ì´ˆ ì†Œìš”)")
            scroll_times = 15  # [ì‹¬ì¸µ] ìŠ¤í¬ë¡¤ 15ë²ˆ (ê¹Šê²Œ)
        else:
            scroll_times = 3   # [ì¼ë°˜] ìŠ¤í¬ë¡¤ 3ë²ˆ (ë¹ ë¥´ê²Œ)

        body = driver.find_element(By.TAG_NAME, "body")
        for i in range(scroll_times):
            body.send_keys(Keys.END)
            time.sleep(1.2) # ë¡œë”© ì‹œê°„ í™•ë³´
        
        time.sleep(2) # ìŠ¤í¬ë¡¤ ëë‚œ í›„ ë°ì´í„° ì•ˆì •í™” ëŒ€ê¸°
        # -----------------------------------------------------------

        articles = driver.find_elements(By.CSS_SELECTOR, "li.bx")
        
        keyword_count = 0
        
        for article in articles:
            try:
                # 1. ì¹´í˜ëª… ì¶”ì¶œ
                cafe_name = ""
                try: cafe_name = article.find_element(By.CSS_SELECTOR, "a.txt_name").text
                except: 
                    try: cafe_name = article.find_element(By.CSS_SELECTOR, "a.name").text
                    except: pass

                # 2. ì¹´í˜ëª… í•„í„° (í…ŒìŠ¬ë¼, ì „ê¸°ì°¨, EV)
                is_target_cafe = False
                for target in TARGET_CAFE_KEYWORDS:
                    if target in cafe_name:
                        is_target_cafe = True
                        break
                if not is_target_cafe: continue

                # 3. ìµœì‹ ê¸€ í™•ì¸
                box_text = article.text
                if not any(x in box_text for x in ["ë¶„ ì „", "ì‹œê°„ ì „", "ë°©ê¸ˆ ì „"]):
                    continue
                
                date_str = datetime.now().strftime("%Y-%m-%d") + " (New)"

                # 4. ì œëª©/ë§í¬
                try:
                    title_ele = article.find_element(By.CSS_SELECTOR, "a.title_link")
                    title = title_ele.text
                    link = title_ele.get_attribute("href")
                except: continue

                if any(bad_word in title for bad_word in EXCLUDE_WORDS): continue

                data_list.append({
                    "ì‘ì„±ì¼": date_str,
                    "í‚¤ì›Œë“œ": keyword, 
                    "ì¹´í˜ëª…": cafe_name,
                    "ì œëª©": title,
                    "ë§í¬": link,
                    "ìˆ˜ì§‘ì‹œì ": datetime.now().strftime("%Y-%m-%d %H:%M")
                })
                # ë¡œê·¸ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì§„í–‰ìƒí™© íŒŒì•…ì´ ì–´ë ¤ìš°ë¯€ë¡œ 5ê±´ ë‹¨ìœ„ë¡œë§Œ ì¶œë ¥
                # print(f"   âœ… [ìˆ˜ì§‘] {cafe_name} | {title[:15]}...")
                keyword_count += 1

            except Exception: continue
            
        if keyword_count == 0:
            print(f"   ğŸ’¨ '{keyword}' ê²°ê³¼ 0ê±´. (í•„í„°ë§ ë¨)")
        else:
            print(f"   âœ¨ '{keyword}' ì™„ë£Œ: ì´ {keyword_count}ê±´ ìˆ˜ì§‘ë¨")
            
        time.sleep(1)

except Exception as e:
    print(f"ì—ëŸ¬ ë°œìƒ: {e}")
finally:
    driver.quit()

# ======================================================
# [ì €ì¥ ë° GitHub ìë™ ì—…ë¡œë“œ]
# ======================================================
def auto_push_to_github():
    try:
        print("\nğŸ™ GitHub ì—…ë¡œë“œ ì‹œì‘...")
        subprocess.run(["git", "add", FILE_NAME], check=True)
        commit_message = f"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        try:
            subprocess.run(["git", "commit", "-m", commit_message], check=True)
        except subprocess.CalledProcessError:
            print("   -> (GitHub) ë³€ê²½ ì‚¬í•­ ì—†ìŒ")
            return
        subprocess.run(["git", "push"], check=True)
        print("âœ… GitHub Push ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ GitHub ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

if data_list:
    df_new = pd.DataFrame(data_list)
    # [ì¤‘ìš”] ì»¬ëŸ¼ ìˆœì„œë¥¼ ê³ ì •í•˜ì—¬ ë°ì´í„° ë°€ë¦¼ ë°©ì§€
    df_new = df_new[["ì‘ì„±ì¼", "í‚¤ì›Œë“œ", "ì¹´í˜ëª…", "ì œëª©", "ë§í¬", "ìˆ˜ì§‘ì‹œì "]]

    if os.path.exists(FILE_NAME):
        try:
            df_old = pd.read_csv(FILE_NAME)
            # ê¸°ì¡´ íŒŒì¼ í˜•ì‹ì´ ë§ì§€ ì•Šìœ¼ë©´ ë®ì–´ì“°ê¸° (ë°ì´í„° ë°€ë¦¼ ë°©ì§€)
            if "í‚¤ì›Œë“œ" not in df_old.columns or "ì¹´í˜ëª…" not in df_old.columns:
                 print("\nâš ï¸ êµ¬ë²„ì „ íŒŒì¼ ê°ì§€! íŒŒì¼ì„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                 df_new.to_csv(FILE_NAME, mode='w', header=True, index=False, encoding="utf-8-sig")
            else:
                existing_links = df_old['ë§í¬'].tolist()
                df_final = df_new[~df_new['ë§í¬'].isin(existing_links)]
                if not df_final.empty:
                    df_final.to_csv(FILE_NAME, mode='a', header=False, index=False, encoding="utf-8-sig")
                    print(f"\nâœ… ë¡œì»¬ ì €ì¥ ì™„ë£Œ ({len(df_final)}ê±´ ì¶”ê°€)")
                    auto_push_to_github()
                else:
                    print("\nğŸ‘Œ ìƒˆë¡œìš´ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤ (ì „ì²´ ì¤‘ë³µ).")
        except:
            df_new.to_csv(FILE_NAME, mode='w', header=True, index=False, encoding="utf-8-sig")
            auto_push_to_github()
    else:
        df_new.to_csv(FILE_NAME, mode='w', header=True, index=False, encoding="utf-8-sig")
        print(f"\nâœ… ì‹ ê·œ íŒŒì¼ ìƒì„± ì™„ë£Œ.")
        auto_push_to_github()
else:
    print("\nğŸ’¤ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
